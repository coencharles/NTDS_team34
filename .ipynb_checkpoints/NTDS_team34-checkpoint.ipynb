{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [NTDS'18] Team project\n",
    "[ntds'18]: https://github.com/mdeff/ntds_2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Students\n",
    "\n",
    "* Team: `<34>`\n",
    "* Students: `<Valentin Morel, Xavier Sieber, Cédric Schumacher, Charles-Théophile Coen>`\n",
    "* Dataset: `<Terrorist attack>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import scipy.sparse.linalg\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from pyunlocbox import functions, solvers\n",
    "from scipy.optimize import minimize as opt\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.cluster import KMeans, SpectralClustering, Birch\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import hdbscan\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0.1\n",
    "This part consists of creating or loading the different objects that we need for further tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "features = pd.read_csv('TerrorAttack/terrorist_attack.nodes',delim_whitespace=' ',header = None,engine='python')\n",
    "features = features.drop( columns=0)\n",
    "features = features.drop(columns=107)\n",
    "\n",
    "# Labels\n",
    "labels = pd.read_csv('TerrorAttack/terrorist_attack.nodes',delim_whitespace=' ',header = None,engine='python')[[107]]\n",
    "labels[107] = labels[107].map(lambda x: x.lstrip('http://counterterror.mindswap.org2005/ict_events.owl#'))\n",
    "\n",
    "# Locations\n",
    "adjacency_location = np.load('adjacency_location.npy')\n",
    "adjacency_location[881][967] = 1\n",
    "adjacency_location[967][881] = 1\n",
    "adjacency_location[582][587] = 1\n",
    "adjacency_location[587][582] = 1\n",
    "n_nodes = len(adjacency_location)\n",
    "\n",
    "location = np.zeros(n_nodes)\n",
    "number_loc = 0\n",
    "location[0] = number_loc\n",
    "index = []\n",
    "for i in range(0,n_nodes):\n",
    "    #if i != 0:\n",
    "    if not location[i] in location[0:i]:\n",
    "        number_loc += 1\n",
    "        location[i] = number_loc\n",
    "    else:\n",
    "        index.append(i)\n",
    "\n",
    "    if not location[i] in location[0:i]:\n",
    "        for j in range(i,n_nodes):\n",
    "            if adjacency_location[i,j] == 1:\n",
    "                location[j] = location[i]\n",
    "\n",
    "# Distance matrix – 106 features\n",
    "X = features\n",
    "distances = pdist(X.values, metric='cosine')\n",
    "kernel_width = distances.mean()\n",
    "weights_106 = np.exp(-distances**2 / kernel_width**2)\n",
    "adjacency_features = squareform(weights_106) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0.2\n",
    "This part is dedicated to the different functions used troughout this whole project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_weighted(i,j):\n",
    "    return adjacency_weights[i,j]\n",
    "\n",
    "def clustering_location (adj,Ltype,k,typ,gt,plot):\n",
    "    \n",
    "    # Creation of the Laplacian \n",
    "    adjacency = adj.A\n",
    "    degree=adjacency.sum(axis=0)\n",
    "    adjacency = sparse.csr_matrix(adjacency)\n",
    "    \n",
    "    D = sparse.diags(degree)\n",
    "    D_rw=sparse.diags(1/degree)\n",
    "    D_n = sparse.diags(1/np.sqrt(degree))\n",
    "    L = D - adjacency\n",
    "    L_rw = D_rw.dot(L)\n",
    "    L_n = D_n.dot(L.dot(D_n))\n",
    "    \n",
    "    if Ltype=='std':\n",
    "        Lap=L\n",
    "    if Ltype=='rw':\n",
    "        Lap=L_rw\n",
    "    if Ltype=='norm':\n",
    "        Lap=L_n\n",
    "    \n",
    "    # Spectral decomposition\n",
    "    e, U = np.linalg.eigh(Lap.A)\n",
    "    \n",
    "    # Clustering\n",
    "    if typ == 'sc':\n",
    "        my_clust = SpectralClustering(k, affinity='precomputed')\n",
    "    if typ == 'bi':\n",
    "        my_clust = Birch(threshold= 0.8, n_clusters = k)\n",
    "    if typ == 'hd':\n",
    "        my_clust = hdbscan.HDBSCAN(min_cluster_size=k)\n",
    "    if typ == 'km':\n",
    "        my_clust = KMeans(k)\n",
    "    \n",
    "    my_clust.fit_predict(adjacency.A)\n",
    "    \n",
    "    # Plotting of the data with ground truth and the clustering attribution\n",
    "    if plot:\n",
    "        fig = plt.figure(figsize=(12,12))\n",
    "        ax = Axes3D(fig)\n",
    "        ax.scatter(U[:,1],U[:,2],U[:,3],c=gt,cmap='rainbow')\n",
    "        \n",
    "        fig2 = plt.figure(figsize=(12,12))\n",
    "        ax2 = Axes3D(fig2)\n",
    "        ax2.scatter(U[:,1],U[:,2],U[:,3],c=my_clust.fit_predict(adjacency.A),cmap='rainbow')\n",
    "        \n",
    "    \n",
    "    return my_clust\n",
    "\n",
    "def clustering_label(feature,kernel,gt,Ltype,k,typ,plot):\n",
    "    \n",
    "    # Creating adjacency\n",
    "    distances = pdist(feature, metric=kernel)\n",
    "    kernel_width = distances.mean()\n",
    "    weights = np.exp(-distances**2 / kernel_width**2)\n",
    "    adjacency = squareform(weights)\n",
    "    \n",
    "    # Creation of the Laplacian \n",
    "    degree=adjacency.sum(axis=0)\n",
    "    adjacency = sparse.csr_matrix(adjacency)\n",
    "    \n",
    "    D = sparse.diags(degree)\n",
    "    D_rw=sparse.diags(1/degree)\n",
    "    D_n = sparse.diags(1/np.sqrt(degree))\n",
    "    L = D - adjacency\n",
    "    L_rw = D_rw.dot(L)\n",
    "    L_n = D_n.dot(L.dot(D_n))\n",
    "    \n",
    "    if Ltype=='std':\n",
    "        Lap=L\n",
    "    if Ltype=='rw':\n",
    "        Lap=L_rw\n",
    "    if Ltype=='norm':\n",
    "        Lap=L_n\n",
    "    \n",
    "    # Spectral decomposition\n",
    "    e, U = np.linalg.eigh(Lap.A)\n",
    "    \n",
    "    # Clustering\n",
    "    if typ == 'sc':\n",
    "        my_clust = SpectralClustering(k, affinity='precomputed')\n",
    "    if typ == 'bi':\n",
    "        my_clust = Birch(threshold= 0.8, n_clusters = k)\n",
    "    if typ == 'hd':\n",
    "        my_clust = hdbscan.HDBSCAN(min_cluster_size=k)\n",
    "    if typ == 'km':\n",
    "        my_clust = KMeans(k)\n",
    "\n",
    "    my_clust.fit_predict(adjacency.A)\n",
    "    \n",
    "    if plot:\n",
    "        fig = plt.figure(figsize=(12,12))\n",
    "        ax = Axes3D(fig)\n",
    "        ax.scatter(U[:,1],U[:,2],U[:,3],c=gt,cmap='rainbow')\n",
    "        \n",
    "        fig2 = plt.figure(figsize=(12,12))\n",
    "        ax2 = Axes3D(fig2)\n",
    "        ax2.scatter(U[:,1],U[:,2],U[:,3],c=my_clust.fit_predict(adjacency.A),cmap='rainbow')\n",
    "    \n",
    "    return my_clust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.0\n",
    "In this project, each attack has 106 features and two types of labels: a location, and a type of attack. This part consists of doing basic analysis of these two labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
